{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ead374c",
   "metadata": {},
   "source": [
    "## Implement collaborative filtering recommender that predicts user rating for an item.\n",
    "\n",
    "- Test different configurations (e.g. different number of nearest neighbors, different similarities)\n",
    "- Evaluate them by usage of (implemented by yourself) MAE and RMSE\n",
    "- Choose between cross-validation and hold-out validation to perform you evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102acb96",
   "metadata": {},
   "source": [
    "### About the dataset:\n",
    "This data set consists of:\n",
    "\t* 100,000 ratings (1-5) from 943 users on 1682 movies. \n",
    "\t* Each user has rated at least 20 movies. \n",
    "        * Simple demographic info for the users (age, gender, occupation, zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ef89cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade scikit-surprise numpy\n",
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, Prediction\n",
    "from surprise import KNNBasic, BaselineOnly\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.model_selection import KFold\n",
    "from surprise import accuracy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce0ebe34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the MovieLens 100k dataset (standard in Surprise)\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7002814c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.dataset.DatasetAutoFolds at 0x11cc62d50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfd4f504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom performance metrics\n",
    "def calculate_mae(predictions):\n",
    "    \"\"\"Calculates Mean Absolute Error (MAE) for a list of predictions.\"\"\"\n",
    "    if not predictions:\n",
    "        return 0\n",
    "    # The 'r_ui' is the true rating, and 'est' is the estimated rating.\n",
    "    errors = [abs(true_rating - est_rating) for (_, _, true_rating, est_rating, _) in predictions]\n",
    "    return np.mean(errors)\n",
    "\n",
    "def calculate_rmse(predictions):\n",
    "    \"\"\"Calculates Root Mean Squared Error (RMSE) for a list of predictions.\"\"\"\n",
    "    if not predictions:\n",
    "        return 0\n",
    "    # The 'r_ui' is the true rating, and 'est' is the estimated rating.\n",
    "    squared_errors = [(true_rating - est_rating)**2 for (_, _, true_rating, est_rating, _) in predictions]\n",
    "    return np.sqrt(np.mean(squared_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9859551a",
   "metadata": {},
   "source": [
    "### Testing and Evaluation\n",
    "We will use 5-fold cross-validation and test different combinations of collaborative filtering settings:\n",
    "- Similarity Metrics: cosine, MSD, and pearson\n",
    "- Number of Neighbors (k): 20, 40, and 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbc0b17",
   "metadata": {},
   "source": [
    "#### We will use the User-Based Collaborative Filtering approach (user_based=True) with the KNNBasic algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de6a766e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting cross-validation and evaluation for all configurations...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "# Define cross-validation splitter\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "# Define configurations to test\n",
    "similarity_metrics = ['cosine', 'MSD', 'pearson']\n",
    "k_values = [20, 40, 60]\n",
    "\n",
    "# Generate all combinations (Cartesian product)\n",
    "combinations = list(itertools.product(similarity_metrics, k_values))\n",
    "\n",
    "# Build the final list of configuration dictionaries using a list comprehension\n",
    "configurations = [\n",
    "    {\n",
    "        'sim_options': {'name': sim, 'user_based': True},\n",
    "        'k': k\n",
    "    }\n",
    "    for sim, k in combinations\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Starting cross-validation and evaluation for all configurations...\")\n",
    "\n",
    "for config in configurations:\n",
    "    sim_name = config['sim_options']['name']\n",
    "    k_val = config['k']\n",
    "\n",
    "    # Set the algorithm with current configuration\n",
    "    algo = KNNBasic(k=k_val, sim_options=config['sim_options'], random_state=42)\n",
    "\n",
    "    # Perform 5-fold cross-validation\n",
    "    mae_list = []\n",
    "    rmse_list = []\n",
    "\n",
    "    for trainset, testset in kf.split(data):\n",
    "        # Train the algorithm\n",
    "        algo.fit(trainset)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        predictions = algo.test(testset)\n",
    "\n",
    "        # Calculate MAE and RMSE using the custom functions\n",
    "        mae_fold = calculate_mae(predictions)\n",
    "        rmse_fold = calculate_rmse(predictions)\n",
    "\n",
    "        mae_list.append(mae_fold)\n",
    "        rmse_list.append(rmse_fold)\n",
    "\n",
    "    # Calculate average MAE and RMSE over all folds\n",
    "    avg_mae = np.mean(mae_list)\n",
    "    avg_rmse = np.mean(rmse_list)\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        'Similarity': sim_name,\n",
    "        'k (Neighbors)': k_val,\n",
    "        'Mean MAE': avg_mae,\n",
    "        'Mean RMSE': avg_rmse\n",
    "    })\n",
    "\n",
    "print(\"Evaluation complete.\")\n",
    "\n",
    "# Convert results to a DataFrame for clean display\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61ed4722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "      <th>k (Neighbors)</th>\n",
       "      <th>Mean MAE</th>\n",
       "      <th>Mean RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cosine</td>\n",
       "      <td>20</td>\n",
       "      <td>0.809675</td>\n",
       "      <td>1.025230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cosine</td>\n",
       "      <td>40</td>\n",
       "      <td>0.804390</td>\n",
       "      <td>1.017077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cosine</td>\n",
       "      <td>60</td>\n",
       "      <td>0.804802</td>\n",
       "      <td>1.016486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSD</td>\n",
       "      <td>20</td>\n",
       "      <td>0.770803</td>\n",
       "      <td>0.976807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSD</td>\n",
       "      <td>40</td>\n",
       "      <td>0.773483</td>\n",
       "      <td>0.978931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MSD</td>\n",
       "      <td>60</td>\n",
       "      <td>0.778333</td>\n",
       "      <td>0.983958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pearson</td>\n",
       "      <td>20</td>\n",
       "      <td>0.808883</td>\n",
       "      <td>1.019592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pearson</td>\n",
       "      <td>40</td>\n",
       "      <td>0.803166</td>\n",
       "      <td>1.011994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pearson</td>\n",
       "      <td>60</td>\n",
       "      <td>0.802392</td>\n",
       "      <td>1.010806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Similarity  k (Neighbors)  Mean MAE  Mean RMSE\n",
       "0     cosine             20  0.809675   1.025230\n",
       "1     cosine             40  0.804390   1.017077\n",
       "2     cosine             60  0.804802   1.016486\n",
       "3        MSD             20  0.770803   0.976807\n",
       "4        MSD             40  0.773483   0.978931\n",
       "5        MSD             60  0.778333   0.983958\n",
       "6    pearson             20  0.808883   1.019592\n",
       "7    pearson             40  0.803166   1.011994\n",
       "8    pearson             60  0.802392   1.010806"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da427623",
   "metadata": {},
   "source": [
    "Best performing combination: MSD similarity, 20 Neighbors. MAE = 0.770803, RMSE = 0.976807"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f786fcb",
   "metadata": {},
   "source": [
    "#### Baseline model - Naive predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "616ead87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Estimating biases using als...\n",
      "Evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "# We use BaselineOnly, which predicts r_ui = global_mean + user_bias + item_bias, item_bias is related to the item's average rating.\n",
    "baseline = []\n",
    "\n",
    "algo = BaselineOnly()\n",
    "\n",
    "mae_list = []\n",
    "rmse_list = []\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Use the custom-implemented functions\n",
    "    mae_fold = calculate_mae(predictions)\n",
    "    rmse_fold = calculate_rmse(predictions)\n",
    "\n",
    "    mae_list.append(mae_fold)\n",
    "    rmse_list.append(rmse_fold)\n",
    "\n",
    "# Calculate average MAE and RMSE over all folds\n",
    "avg_mae = np.mean(mae_list)\n",
    "avg_rmse = np.mean(rmse_list)\n",
    "\n",
    "# Store results\n",
    "baseline.append({\n",
    "    'Mean MAE': avg_mae,\n",
    "    'Mean RMSE': avg_rmse\n",
    "})\n",
    "\n",
    "print(\"Evaluation complete.\")\n",
    "\n",
    "baseline_df = pd.DataFrame(baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6ba5a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean MAE</th>\n",
       "      <th>Mean RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.748089</td>\n",
       "      <td>0.943637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean MAE  Mean RMSE\n",
       "0  0.748089   0.943637"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d86b0ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_average_predictions(trainset, testset):\n",
    "    \"\"\"\n",
    "    Predicts a rating for a user/item pair solely as the average of\n",
    "    that item's ratings in the training set.\n",
    "    \"\"\"\n",
    "    # Calculate global mean for cases where an item is new (cold start)\n",
    "    global_mean = trainset.global_mean\n",
    "\n",
    "    # 1. Calculate item averages from the training set\n",
    "    item_ratings = {}\n",
    "    # trainset.all_ratings() returns inner IDs (iid)\n",
    "    for uid, iid, rating in trainset.all_ratings():\n",
    "        # iid is the inner item ID here, which we use as the key\n",
    "        if iid not in item_ratings:\n",
    "            item_ratings[iid] = []\n",
    "        item_ratings[iid].append(rating)\n",
    "\n",
    "    item_averages = {\n",
    "        iid: np.mean(ratings)\n",
    "        for iid, ratings in item_ratings.items()\n",
    "    }\n",
    "\n",
    "    # 2. Generate predictions for the test set\n",
    "    predictions = []\n",
    "    for uid, iid, true_r in testset:\n",
    "        # Get the predicted rating (est)\n",
    "        # iid is already the inner ID, which is the key in item_averages.\n",
    "        # We look up the average rating for the item, falling back to global mean if the item is not in the training set.\n",
    "        est = item_averages.get(iid, global_mean)\n",
    "\n",
    "        # Create a Prediction object (required format for custom MAE/RMSE)\n",
    "        # We convert inner IDs back to raw IDs for the final Prediction object\n",
    "        pred = Prediction(uid=trainset.to_raw_uid(uid), iid=trainset.to_raw_iid(iid), r_ui=true_r, est=est, details={})\n",
    "        predictions.append(pred)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3838e1d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "907 is not a valid inner id.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/recommendation_system/Recommendation-System/lib/python3.12/site-packages/surprise/trainset.py:135\u001b[39m, in \u001b[36mTrainset.to_raw_uid\u001b[39m\u001b[34m(self, iuid)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner2raw_id_users\u001b[49m\u001b[43m[\u001b[49m\u001b[43miuid\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[31mKeyError\u001b[39m: '907'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m predictions = \u001b[43mget_item_average_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m baseline_avg = []\n\u001b[32m      4\u001b[39m mae_list = []\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mget_item_average_predictions\u001b[39m\u001b[34m(trainset, testset)\u001b[39m\n\u001b[32m     29\u001b[39m     est = item_averages.get(iid, global_mean)\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Create a Prediction object (required format for custom MAE/RMSE)\u001b[39;00m\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# We convert inner IDs back to raw IDs for the final Prediction object\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     pred = Prediction(uid=\u001b[43mtrainset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_raw_uid\u001b[49m\u001b[43m(\u001b[49m\u001b[43muid\u001b[49m\u001b[43m)\u001b[49m, iid=trainset.to_raw_iid(iid), r_ui=true_r, est=est, details={})\n\u001b[32m     34\u001b[39m     predictions.append(pred)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/recommendation_system/Recommendation-System/lib/python3.12/site-packages/surprise/trainset.py:137\u001b[39m, in \u001b[36mTrainset.to_raw_uid\u001b[39m\u001b[34m(self, iuid)\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inner2raw_id_users[iuid]\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(iuid) + \u001b[33m\"\u001b[39m\u001b[33m is not a valid inner id.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: 907 is not a valid inner id."
     ]
    }
   ],
   "source": [
    "predictions = get_item_average_predictions(trainset, testset)\n",
    "\n",
    "baseline_avg = []\n",
    "mae_list = []\n",
    "rmse_list = []\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Use the custom-implemented functions\n",
    "    mae_fold = calculate_mae(predictions)\n",
    "    rmse_fold = calculate_rmse(predictions)\n",
    "\n",
    "    mae_list.append(mae_fold)\n",
    "    rmse_list.append(rmse_fold)\n",
    "\n",
    "# Calculate average MAE and RMSE over all folds\n",
    "avg_mae = np.mean(mae_list)\n",
    "avg_rmse = np.mean(rmse_list)\n",
    "\n",
    "# Store results\n",
    "baseline_avg.append({\n",
    "    'Mean MAE': avg_mae,\n",
    "    'Mean RMSE': avg_rmse\n",
    "})\n",
    "\n",
    "print(\"Evaluation complete.\")\n",
    "\n",
    "baseline_avg_df = pd.DataFrame(baseline_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "996aa5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MovieLens 100k data...\n",
      "Starting evaluation of 9 CF models...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Starting evaluation of the Naive Item Average Baseline...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "877 is not a valid inner id.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/recommendation_system/Recommendation-System/lib/python3.12/site-packages/surprise/trainset.py:135\u001b[39m, in \u001b[36mTrainset.to_raw_uid\u001b[39m\u001b[34m(self, iuid)\u001b[39m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inner2raw_id_users\u001b[49m\u001b[43m[\u001b[49m\u001b[43miuid\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[31mKeyError\u001b[39m: '877'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 120\u001b[39m\n\u001b[32m    116\u001b[39m naive_rmse_list = []\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m trainset, testset \u001b[38;5;129;01min\u001b[39;00m kf.split(data):\n\u001b[32m    119\u001b[39m     \u001b[38;5;66;03m# Get predictions using the custom function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     predictions = \u001b[43mget_item_average_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtestset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m     naive_mae_list.append(calculate_mae(predictions))\n\u001b[32m    123\u001b[39m     naive_rmse_list.append(calculate_rmse(predictions))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mget_item_average_predictions\u001b[39m\u001b[34m(trainset, testset)\u001b[39m\n\u001b[32m     58\u001b[39m     est = item_averages.get(iid, global_mean)\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# Create a Prediction object (required format for custom MAE/RMSE)\u001b[39;00m\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# We convert inner IDs back to raw IDs for the final Prediction object\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m     pred = Prediction(uid=\u001b[43mtrainset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_raw_uid\u001b[49m\u001b[43m(\u001b[49m\u001b[43muid\u001b[49m\u001b[43m)\u001b[49m, iid=trainset.to_raw_iid(iid), r_ui=true_r, est=est, details={})\n\u001b[32m     63\u001b[39m     predictions.append(pred)\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/recommendation_system/Recommendation-System/lib/python3.12/site-packages/surprise/trainset.py:137\u001b[39m, in \u001b[36mTrainset.to_raw_uid\u001b[39m\u001b[34m(self, iuid)\u001b[39m\n\u001b[32m    135\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inner2raw_id_users[iuid]\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(iuid) + \u001b[33m\"\u001b[39m\u001b[33m is not a valid inner id.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: 877 is not a valid inner id."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Prediction\n",
    "from surprise import KNNBasic\n",
    "from surprise.model_selection import KFold\n",
    "import numpy as np\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "# Filter out common pandas/surprise warnings during cross-validation runs\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Custom Evaluation Functions ---\n",
    "def calculate_mae(predictions):\n",
    "    \"\"\"Calculates Mean Absolute Error (MAE) for a list of predictions.\"\"\"\n",
    "    if not predictions:\n",
    "        return 0\n",
    "    # The 'r_ui' is the true rating, and 'est' is the estimated rating.\n",
    "    errors = [abs(true_rating - est_rating) for (_, _, true_rating, est_rating, _) in predictions]\n",
    "    return np.mean(errors)\n",
    "\n",
    "def calculate_rmse(predictions):\n",
    "    \"\"\"Calculates Root Mean Squared Error (RMSE) for a list of predictions.\"\"\"\n",
    "    if not predictions:\n",
    "        return 0\n",
    "    # The 'r_ui' is the true rating, and 'est' is the estimated rating.\n",
    "    squared_errors = [(true_rating - est_rating)**2 for (_, _, true_rating, est_rating, _) in predictions]\n",
    "    return np.sqrt(np.mean(squared_errors))\n",
    "\n",
    "# --- 2. Custom Item Average Predictor Function ---\n",
    "def get_item_average_predictions(trainset, testset):\n",
    "    \"\"\"\n",
    "    Predicts a rating for a user/item pair solely as the average of\n",
    "    that item's ratings in the training set.\n",
    "    \"\"\"\n",
    "    # Calculate global mean for cases where an item is new (cold start)\n",
    "    global_mean = trainset.global_mean\n",
    "\n",
    "    # 1. Calculate item averages from the training set\n",
    "    item_ratings = {}\n",
    "    # trainset.all_ratings() returns inner IDs (iid)\n",
    "    for uid, iid, rating in trainset.all_ratings():\n",
    "        # iid is the inner item ID here, which we use as the key\n",
    "        if iid not in item_ratings:\n",
    "            item_ratings[iid] = []\n",
    "        item_ratings[iid].append(rating)\n",
    "\n",
    "    item_averages = {\n",
    "        iid: np.mean(ratings)\n",
    "        for iid, ratings in item_ratings.items()\n",
    "    }\n",
    "\n",
    "    # 2. Generate predictions for the test set\n",
    "    predictions = []\n",
    "    for uid, iid, true_r in testset:\n",
    "        # Get the predicted rating (est)\n",
    "        # iid is already the inner ID, which is the key in item_averages.\n",
    "        # We look up the average rating for the item, falling back to global mean if the item is not in the training set.\n",
    "        est = item_averages.get(iid, global_mean)\n",
    "\n",
    "        # Create a Prediction object (required format for custom MAE/RMSE)\n",
    "        # We convert inner IDs back to raw IDs for the final Prediction object\n",
    "        pred = Prediction(uid=trainset.to_raw_uid(uid), iid=trainset.to_raw_iid(iid), r_ui=true_r, est=est, details={})\n",
    "        predictions.append(pred)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# --- 3. Setup and Data Loading ---\n",
    "print(\"Loading MovieLens 100k data...\")\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "results = []\n",
    "all_folds_predictions = []\n",
    "\n",
    "# --- 4. Configuration Generation using itertools ---\n",
    "similarity_metrics = ['cosine', 'MSD', 'pearson']\n",
    "k_values = [20, 40, 60]\n",
    "cf_combinations = list(itertools.product(similarity_metrics, k_values))\n",
    "\n",
    "cf_configurations = [\n",
    "    {\n",
    "        'Algorithm': 'KNNBasic',\n",
    "        'Model Details': f\"{sim} (k={k})\",\n",
    "        'sim_options': {'name': sim, 'user_based': True},\n",
    "        'k': k\n",
    "    }\n",
    "    for sim, k in cf_combinations\n",
    "]\n",
    "\n",
    "# --- 5. Evaluation Loop ---\n",
    "print(f\"Starting evaluation of {len(cf_configurations)} CF models...\")\n",
    "\n",
    "for config in cf_configurations:\n",
    "    # --- Collaborative Filtering (KNNBasic) Evaluation ---\n",
    "    algo = KNNBasic(k=config['k'], sim_options=config['sim_options'], random_state=42)\n",
    "    mae_list = []\n",
    "    rmse_list = []\n",
    "\n",
    "    for trainset, testset in kf.split(data):\n",
    "        algo.fit(trainset)\n",
    "        predictions = algo.test(testset)\n",
    "\n",
    "        mae_list.append(calculate_mae(predictions))\n",
    "        rmse_list.append(calculate_rmse(predictions))\n",
    "\n",
    "    results.append({\n",
    "        'Algorithm': config['Algorithm'],\n",
    "        'Model Details': config['Model Details'],\n",
    "        'Mean MAE': np.mean(mae_list),\n",
    "        'Mean RMSE': np.mean(rmse_list)\n",
    "    })\n",
    "\n",
    "# --- 6. Naive Baseline Evaluation ---\n",
    "print(\"Starting evaluation of the Naive Item Average Baseline...\")\n",
    "naive_mae_list = []\n",
    "naive_rmse_list = []\n",
    "\n",
    "for trainset, testset in kf.split(data):\n",
    "    # Get predictions using the custom function\n",
    "    predictions = get_item_average_predictions(trainset, testset)\n",
    "\n",
    "    naive_mae_list.append(calculate_mae(predictions))\n",
    "    naive_rmse_list.append(calculate_rmse(predictions))\n",
    "\n",
    "results.append({\n",
    "    'Algorithm': 'Naive Baseline',\n",
    "    'Model Details': 'Strict Item Average',\n",
    "    'Mean MAE': np.mean(naive_mae_list),\n",
    "    'Mean RMSE': np.mean(naive_rmse_list)\n",
    "})\n",
    "\n",
    "print(\"Evaluation complete.\")\n",
    "\n",
    "# --- 7. Final Results Summary ---\n",
    "results_df = pd.DataFrame(results).sort_values(by='Mean RMSE')\n",
    "print(\"\\n--- Summary of All Results ---\")\n",
    "print(results_df.to_markdown(index=False))\n",
    "\n",
    "# --- Finding Best CF and Baseline for Reporting ---\n",
    "best_cf = results_df[results_df['Algorithm'] == 'KNNBasic'].iloc[0]\n",
    "naive_baseline = results_df[results_df['Algorithm'] == 'Naive Baseline'].iloc[0]\n",
    "\n",
    "# These are the original CF results the user provided, used for the report comparison\n",
    "original_cf_best = {'Mean MAE': 0.770803, 'Mean RMSE': 0.976807}\n",
    "\n",
    "print(\"\\nBest Collaborative Filtering (CF) Model (from original results):\")\n",
    "print(f\"  RMSE: {original_cf_best['Mean RMSE']:.4f}, MAE: {original_cf_best['Mean MAE']:.4f}\")\n",
    "print(\"Strict Naive Baseline Model (New):\")\n",
    "print(f\"  RMSE: {naive_baseline['Mean RMSE']:.4f}, MAE: {naive_baseline['Mean MAE']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Recommendation-System",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
